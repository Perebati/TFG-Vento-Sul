{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6007, 36, 3)\n",
      "y_train shape: (6007, 1)\n",
      "X_test shape: (1472, 36, 3)\n",
      "y_test shape: (1472, 1)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dropout, LayerNormalization, Dense, TimeDistributed, RepeatVector, MultiHeadAttention, Concatenate, Bidirectional, Attention, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras_tuner import HyperParameters, Hyperband\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Carregar dados\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Converter 'id' em datetime e definir como índice\n",
    "data['timestamp'] = pd.to_datetime(data['id'], errors='coerce')\n",
    "data.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Selecionar variáveis relevantes\n",
    "variables = data[['ws100', 'humid', 'wdisp100']]\n",
    "\n",
    "# Padronização dos dados usando MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "variables_scaled = scaler.fit_transform(variables)\n",
    "\n",
    "# Parâmetros para sequências de entrada e saída\n",
    "sequence_length = 36   # Janela de aprendizado de 36 passos de tempo\n",
    "step_ahead = 6         # Previsão para o sexto passo (1 hora de antecedência)\n",
    "split_ratio = 0.80      # 80% para treinamento e 20% para teste\n",
    "\n",
    "# Divisão dos dados em treinamento e teste\n",
    "split_index = int(len(variables_scaled) * split_ratio)\n",
    "train_data = variables_scaled[:split_index]\n",
    "test_data = variables_scaled[split_index:]\n",
    "\n",
    "# Função para preparar sequências de dados para previsão de um passo específico\n",
    "def create_sequences_single_ahead(data, seq_length, step_ahead=6):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - step_ahead + 1):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i + seq_length + step_ahead -1, 0])  # ws100 é a primeira coluna\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Criar sequências para treinamento e teste\n",
    "X_train, y_train = create_sequences_single_ahead(train_data, sequence_length, step_ahead)\n",
    "X_test, y_test = create_sequences_single_ahead(test_data, sequence_length, step_ahead)\n",
    "\n",
    "# Reshape de y_train e y_test para serem compatíveis com a saída do modelo\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "# Valores mínimos e máximos de 'ws100' para inversão da escala\n",
    "ws100_min = scaler.data_min_[0]\n",
    "ws100_max = scaler.data_max_[0]\n",
    "\n",
    "# Número de características\n",
    "num_features = X_train.shape[2]\n",
    "\n",
    "# Verificação das formas dos dados\n",
    "print(f\"X_train shape: {X_train.shape}\")  # Esperado: (num_samples, 36, 5)\n",
    "print(f\"y_train shape: {y_train.shape}\")  # Esperado: (num_samples, 1)\n",
    "print(f\"X_test shape: {X_test.shape}\")    # Esperado: (num_samples, 36, 5)\n",
    "print(f\"y_test shape: {y_test.shape}\")    # Esperado: (num_samples, 1)\")\n",
    "\n",
    "def augment_data(X, y, num_augmented_samples=50):\n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    for i in range(len(y)):\n",
    "        # Inversão da normalização de y\n",
    "        y_inv = y[i] * (ws100_max - ws100_min) + ws100_min\n",
    "        if y_inv < 6.0:\n",
    "            for _ in range(5):  # Aumentar 5 vezes cada amostra\n",
    "                noise = np.random.normal(0, 0.01, X[i].shape)\n",
    "                X_augmented.append(X[i] + noise)\n",
    "                y_augmented.append(y[i])\n",
    "    return np.array(X_augmented), np.array(y_augmented)\n",
    "\n",
    "# Aplicar data augmentation nos dados de treinamento\n",
    "X_train_aug, y_train_aug = augment_data(X_train, y_train)\n",
    "X_train = np.concatenate((X_train, X_train_aug), axis=0)\n",
    "y_train = np.concatenate((y_train, y_train_aug), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição de funções de perdas customizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geração do modelo usando LSTM bidirecional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_cnn(hp):\n",
    "    # Hiperparâmetros com espaços de busca reduzidos\n",
    "    filters = hp.Int('filters', min_value=16, max_value=256, step=16)\n",
    "    kernel_size = hp.Choice('kernel_size', values=[3, 5, 7])\n",
    "    pool_size = hp.Choice('pool_size', values=[2, 3])\n",
    "    units = hp.Int('units', min_value=16, max_value=256, step=16)\n",
    "    learning_rate = hp.Choice('learning_rate', [1e-4, 1e-3, 1e-2])\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    num_heads = hp.Int('num_heads', min_value=2, max_value=6, step=2)\n",
    "    \n",
    "    # Seleção do Otimizador\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    \n",
    "    # Definir ws100_min e ws100_max como constantes do Keras\n",
    "    ws100_min_k = K.constant(ws100_min, dtype='float32')\n",
    "    ws100_max_k = K.constant(ws100_max, dtype='float32')\n",
    "\n",
    "    # Definir a função de perda personalizada dentro da função\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        # Inversão da normalização para obter valores originais\n",
    "        y_true_inv = y_true * (ws100_max_k - ws100_min_k) + ws100_min_k\n",
    "        y_pred_inv = y_pred * (ws100_max_k - ws100_min_k) + ws100_min_k\n",
    "\n",
    "        # Calcula o erro absoluto\n",
    "        error = K.abs(y_true_inv - y_pred_inv)\n",
    "\n",
    "        # Cria um tensor booleano indicando onde y_true_inv < 6 m/s\n",
    "        condition = K.less(y_true_inv, 6.0)\n",
    "\n",
    "        # Define um peso maior para velocidades abaixo de 6 m/s\n",
    "        greater_weight = 5.0  # Peso maior para erros quando y_true_inv < 6 m/s\n",
    "        lesser_weight = 1.0   # Peso normal para outros casos\n",
    "\n",
    "        # Aplica os pesos\n",
    "        weights = K.switch(condition, greater_weight, lesser_weight)\n",
    "        weighted_error = weights * error\n",
    "\n",
    "        # Retorna a média do erro ponderado\n",
    "        return K.mean(weighted_error)\n",
    "    \n",
    "    encoder_inputs = tf.keras.Input(shape=(sequence_length, num_features), name='encoder_input')\n",
    "    x = encoder_inputs\n",
    "\n",
    "    # Camada CNN\n",
    "    x = Conv1D(\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        activation='relu',\n",
    "        padding='same',\n",
    "        kernel_regularizer=l2(1e-4),\n",
    "        name='conv1d_layer'\n",
    "    )(x)\n",
    "\n",
    "    # Camada de Pooling\n",
    "    x = MaxPooling1D(pool_size=pool_size, padding='same', name='maxpool_layer')(x)\n",
    "\n",
    "    # Camada LSTM Bidirecional\n",
    "    x = Bidirectional(LSTM(\n",
    "        units=units,\n",
    "        return_sequences=True,\n",
    "        activation='tanh',\n",
    "        dropout=dropout_rate,\n",
    "        kernel_regularizer=l2(1e-3),\n",
    "        name='bidirectional_lstm_layer'\n",
    "    ))(x)\n",
    "    x = LayerNormalization(name='lstm_norm')(x)\n",
    "\n",
    "    # Encoder State\n",
    "    encoder_state = x[:, -1, :]\n",
    "\n",
    "    # Decoder Input\n",
    "    decoder_inputs = RepeatVector(1, name='repeat_vector')(encoder_state)\n",
    "    decoder_outputs = decoder_inputs\n",
    "\n",
    "    # Camada LSTM no Decoder\n",
    "    decoder_outputs = LSTM(\n",
    "        units=units,\n",
    "        return_sequences=True,\n",
    "        activation='tanh',\n",
    "        dropout=dropout_rate,\n",
    "        kernel_regularizer=l2(1e-3),\n",
    "        name='decoder_lstm_layer'\n",
    "    )(decoder_outputs)\n",
    "    decoder_outputs = LayerNormalization(name='decoder_lstm_norm')(decoder_outputs)\n",
    "\n",
    "    # Atenção Customizada\n",
    "    # Criar máscara de atenção baseada em velocidades abaixo de 6 m/s\n",
    "    ws100_sequence = x[:, :, 0:1]  # Seleciona a primeira característica e mantém a dimensão\n",
    "    ws100_sequence_inv = ws100_sequence * (ws100_max_k - ws100_min_k) + ws100_min_k\n",
    "\n",
    "    attention_weights = tf.where(ws100_sequence_inv < 6.0, 5.0, 1.0)\n",
    "    # Normalizar os pesos de atenção\n",
    "    attention_weights = attention_weights / K.sum(attention_weights, axis=1, keepdims=True)\n",
    "\n",
    "    # Aplicar a máscara de atenção\n",
    "    x_weighted = x * attention_weights\n",
    "\n",
    "    # Camada de Atenção\n",
    "    attention_output = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=units,\n",
    "        name='multi_head_attention'\n",
    "    )(\n",
    "        query=decoder_outputs,\n",
    "        key=x_weighted,\n",
    "        value=x_weighted\n",
    "    )\n",
    "\n",
    "    attention_output = Dropout(dropout_rate, name='attention_dropout')(attention_output)\n",
    "    decoder_concat_input = Concatenate(axis=-1, name='concat_attention')([decoder_outputs, attention_output])\n",
    "\n",
    "    # Camada de Saída\n",
    "    outputs = TimeDistributed(Dense(1, activation='linear'), name='output_layer')(decoder_concat_input)\n",
    "\n",
    "    # Definição do Modelo\n",
    "    model = Model(inputs=encoder_inputs, outputs=outputs, name='Wind_Speed_Predictor_CNN_BiLSTM_Attention')\n",
    "\n",
    "    # Compilação do Modelo com Função de Loss Personalizada\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=custom_loss,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "            tf.keras.metrics.MeanAbsoluteError(name='mae')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Definir o tuner usando Hyperband\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mHyperband\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_model_cnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtuner_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbidirectional_lstm_tuning_updated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Callback para parada antecipada\u001b[39;00m\n\u001b[1;32m     12\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras_tuner/src/tuners/hyperband.py:420\u001b[0m, in \u001b[0;36mHyperband.__init__\u001b[0;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    395\u001b[0m     hypermodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    407\u001b[0m ):\n\u001b[1;32m    408\u001b[0m     oracle \u001b[38;5;241m=\u001b[39m HyperbandOracle(\n\u001b[1;32m    409\u001b[0m         objective,\n\u001b[1;32m    410\u001b[0m         max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    418\u001b[0m         max_consecutive_failed_trials\u001b[38;5;241m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[1;32m    419\u001b[0m     )\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:122\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner\u001b[38;5;241m.\u001b[39mrun_trial:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`hypermodel` if the user defines the search space in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing a `HyperModel` instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m     )\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_model_size \u001b[38;5;241m=\u001b[39m max_model_size\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m optimizer\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:132\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreload()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_populate_initial_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Run in distributed mode.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist_utils\u001b[38;5;241m.\u001b[39mhas_chief_oracle() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dist_utils\u001b[38;5;241m.\u001b[39mis_chief_oracle():\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# Proxies requests to the chief oracle.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Avoid import at the top, to avoid inconsistent protobuf versions.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:192\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mdeclare_hyperparameters(hp)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_space(hp)\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_activate_all_conditions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:149\u001b[0m, in \u001b[0;36mBaseTuner._activate_all_conditions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m hp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_space()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_space(hp)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# Update the recorded scopes.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[85], line 95\u001b[0m, in \u001b[0;36mbuild_model_cnn\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m     92\u001b[0m ws100_sequence \u001b[38;5;241m=\u001b[39m x[:, :, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Seleciona a primeira característica e mantém a dimensão\u001b[39;00m\n\u001b[1;32m     93\u001b[0m ws100_sequence_inv \u001b[38;5;241m=\u001b[39m ws100_sequence \u001b[38;5;241m*\u001b[39m (ws100_max_k \u001b[38;5;241m-\u001b[39m ws100_min_k) \u001b[38;5;241m+\u001b[39m ws100_min_k\n\u001b[0;32m---> 95\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mws100_sequence_inv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Normalizar os pesos de atenção\u001b[39;00m\n\u001b[1;32m     97\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m attention_weights \u001b[38;5;241m/\u001b[39m K\u001b[38;5;241m.\u001b[39msum(attention_weights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras/src/backend/common/keras_tensor.py:138\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "# Definir o tuner usando Hyperband\n",
    "tuner = Hyperband(\n",
    "    build_model_cnn,\n",
    "    objective='val_loss',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='tuner_dir',\n",
    "    project_name='bidirectional_lstm_tuning_updated'\n",
    ")\n",
    "\n",
    "# Callback para parada antecipada\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Iniciar a busca de hiperparâmetros\n",
    "tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Obter os melhores hiperparâmetros\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Construir o melhor modelo com os hiperparâmetros encontrados\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Treinar o melhor modelo\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Salvar o modelo final\n",
    "model_save_path_final = 'best_bidirectional_lstm_model.h5'\n",
    "model.save(model_save_path_final)\n",
    "print(f\"Modelo salvo em: {model_save_path_final}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypertunning do modelo para gerar os melhores parêmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m y_test_inv \u001b[38;5;241m=\u001b[39m y_test \u001b[38;5;241m*\u001b[39m (ws100_max \u001b[38;5;241m-\u001b[39m ws100_min) \u001b[38;5;241m+\u001b[39m ws100_min\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Avaliação das previsões\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_inv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_inv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test_inv, y_pred_inv))\n\u001b[1;32m     13\u001b[0m mape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs((y_test_inv \u001b[38;5;241m-\u001b[39m y_pred_inv) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(y_test_inv, \u001b[38;5;241m1e-6\u001b[39m))) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# Evitar divisão por zero\u001b[39;00m\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:216\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    153\u001b[0m     {\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m ):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    np.float64(0.85...)\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    220\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1058\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m   1064\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1065\u001b[0m         array,\n\u001b[1;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1069\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inversão da padronização\n",
    "y_pred_inv = y_pred * (ws100_max - ws100_min) + ws100_min\n",
    "y_test_inv = y_test * (ws100_max - ws100_min) + ws100_min\n",
    "\n",
    "# Converter para classes: 1 se y < 6 m/s, 0 caso contrário\n",
    "y_pred_class = (y_pred_inv < 6.0).astype(int)\n",
    "y_test_class = (y_test_inv < 6.0).astype(int)\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "# Plotagem das previsões vs valores reais focando em y < 6 m/s\n",
    "indices_below_6 = np.where(y_test_inv < 6.0)[0]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(indices_below_6, y_test_inv[indices_below_6], label='Valor Real')\n",
    "plt.plot(indices_below_6, y_pred_inv[indices_below_6], label='Previsão')\n",
    "plt.legend()\n",
    "plt.title('Comparação entre Valores Reais e Previstos para y < 6 m/s')\n",
    "plt.xlabel('Amostras')\n",
    "plt.ylabel('Velocidade do Vento a 100 metros')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação e plotagem dos gráficos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que fazer:\n",
    "\n",
    "Você tem que falar sobre LSTM, LSTM bidirecional, LSTM encoder-decoder, Loss customizáveis, método automático de seleção do loss.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
