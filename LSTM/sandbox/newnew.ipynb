{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 29s]\n",
      "val_loss: 0.5475764870643616\n",
      "\n",
      "Best val_loss So Far: 0.5475764870643616\n",
      "Total elapsed time: 00h 37m 22s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "192               |160               |units\n",
      "0.0001            |0.001             |learning_rate\n",
      "0.4               |0.3               |dropout_rate\n",
      "2                 |1                 |num_layers\n",
      "adam              |adam              |optimizer\n",
      "2                 |2                 |num_heads\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 81ms/step - custom_mae_sixth: 0.9549 - custom_mape_sixth: 660.6164 - custom_rmse_sixth: 1.1942 - loss: 4.4526 - val_custom_mae_sixth: 0.8113 - val_custom_mape_sixth: 283.7258 - val_custom_rmse_sixth: 0.9911 - val_loss: 3.8469\n",
      "Epoch 2/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - custom_mae_sixth: 0.7753 - custom_mape_sixth: 390.6997 - custom_rmse_sixth: 0.9843 - loss: 3.7022 - val_custom_mae_sixth: 0.7703 - val_custom_mape_sixth: 253.6180 - val_custom_rmse_sixth: 0.9404 - val_loss: 3.5533\n",
      "Epoch 3/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - custom_mae_sixth: 0.7169 - custom_mape_sixth: 382.5486 - custom_rmse_sixth: 0.9067 - loss: 3.4004 - val_custom_mae_sixth: 0.7491 - val_custom_mape_sixth: 261.3348 - val_custom_rmse_sixth: 0.9042 - val_loss: 3.4023\n",
      "Epoch 4/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - custom_mae_sixth: 0.6791 - custom_mape_sixth: 351.6672 - custom_rmse_sixth: 0.8656 - loss: 3.2376 - val_custom_mae_sixth: 0.7394 - val_custom_mape_sixth: 184.6093 - val_custom_rmse_sixth: 0.8847 - val_loss: 3.3460\n",
      "Epoch 5/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - custom_mae_sixth: 0.6331 - custom_mape_sixth: 340.0105 - custom_rmse_sixth: 0.8130 - loss: 3.0845 - val_custom_mae_sixth: 0.7039 - val_custom_mape_sixth: 199.1464 - val_custom_rmse_sixth: 0.8420 - val_loss: 3.2012\n",
      "Epoch 6/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - custom_mae_sixth: 0.6229 - custom_mape_sixth: 331.3882 - custom_rmse_sixth: 0.8018 - loss: 3.0231 - val_custom_mae_sixth: 0.6724 - val_custom_mape_sixth: 178.1225 - val_custom_rmse_sixth: 0.8141 - val_loss: 3.1019\n",
      "Epoch 7/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - custom_mae_sixth: 0.6077 - custom_mape_sixth: 321.5884 - custom_rmse_sixth: 0.7900 - loss: 2.9577 - val_custom_mae_sixth: 0.6663 - val_custom_mape_sixth: 177.7414 - val_custom_rmse_sixth: 0.8109 - val_loss: 3.0422\n",
      "Epoch 8/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - custom_mae_sixth: 0.5984 - custom_mape_sixth: 278.7633 - custom_rmse_sixth: 0.7728 - loss: 2.8859 - val_custom_mae_sixth: 0.6428 - val_custom_mape_sixth: 220.7104 - val_custom_rmse_sixth: 0.7843 - val_loss: 2.9575\n",
      "Epoch 9/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - custom_mae_sixth: 0.5974 - custom_mape_sixth: 320.6245 - custom_rmse_sixth: 0.7742 - loss: 2.8448 - val_custom_mae_sixth: 0.6088 - val_custom_mape_sixth: 219.5036 - val_custom_rmse_sixth: 0.7369 - val_loss: 2.8365\n",
      "Epoch 10/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 88ms/step - custom_mae_sixth: 0.5793 - custom_mape_sixth: 307.3239 - custom_rmse_sixth: 0.7453 - loss: 2.7577 - val_custom_mae_sixth: 0.6419 - val_custom_mape_sixth: 156.7977 - val_custom_rmse_sixth: 0.7742 - val_loss: 2.8815\n",
      "Epoch 11/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - custom_mae_sixth: 0.5743 - custom_mape_sixth: 325.7414 - custom_rmse_sixth: 0.7417 - loss: 2.7047 - val_custom_mae_sixth: 0.6358 - val_custom_mape_sixth: 170.9674 - val_custom_rmse_sixth: 0.7688 - val_loss: 2.7990\n",
      "Epoch 12/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 86ms/step - custom_mae_sixth: 0.5581 - custom_mape_sixth: 283.7362 - custom_rmse_sixth: 0.7252 - loss: 2.6359 - val_custom_mae_sixth: 0.6367 - val_custom_mape_sixth: 189.1036 - val_custom_rmse_sixth: 0.7699 - val_loss: 2.7489\n",
      "Epoch 13/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - custom_mae_sixth: 0.5669 - custom_mape_sixth: 300.1659 - custom_rmse_sixth: 0.7438 - loss: 2.6165 - val_custom_mae_sixth: 0.6052 - val_custom_mape_sixth: 170.8628 - val_custom_rmse_sixth: 0.7412 - val_loss: 2.6558\n",
      "Epoch 14/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - custom_mae_sixth: 0.5562 - custom_mape_sixth: 262.4599 - custom_rmse_sixth: 0.7222 - loss: 2.5379 - val_custom_mae_sixth: 0.5805 - val_custom_mape_sixth: 224.0824 - val_custom_rmse_sixth: 0.7207 - val_loss: 2.5637\n",
      "Epoch 15/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 90ms/step - custom_mae_sixth: 0.5539 - custom_mape_sixth: 262.5724 - custom_rmse_sixth: 0.7216 - loss: 2.4917 - val_custom_mae_sixth: 0.6110 - val_custom_mape_sixth: 180.8540 - val_custom_rmse_sixth: 0.7458 - val_loss: 2.5572\n",
      "Epoch 16/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - custom_mae_sixth: 0.5536 - custom_mape_sixth: 273.0206 - custom_rmse_sixth: 0.7174 - loss: 2.4417 - val_custom_mae_sixth: 0.6060 - val_custom_mape_sixth: 176.8167 - val_custom_rmse_sixth: 0.7429 - val_loss: 2.5133\n",
      "Epoch 17/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - custom_mae_sixth: 0.5518 - custom_mape_sixth: 271.8989 - custom_rmse_sixth: 0.7209 - loss: 2.3976 - val_custom_mae_sixth: 0.5963 - val_custom_mape_sixth: 157.4322 - val_custom_rmse_sixth: 0.7253 - val_loss: 2.4336\n",
      "Epoch 18/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - custom_mae_sixth: 0.5386 - custom_mape_sixth: 277.3961 - custom_rmse_sixth: 0.7067 - loss: 2.3273 - val_custom_mae_sixth: 0.5958 - val_custom_mape_sixth: 190.6153 - val_custom_rmse_sixth: 0.7275 - val_loss: 2.3941\n",
      "Epoch 19/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - custom_mae_sixth: 0.5627 - custom_mape_sixth: 268.7919 - custom_rmse_sixth: 0.7326 - loss: 2.3218 - val_custom_mae_sixth: 0.5964 - val_custom_mape_sixth: 192.4603 - val_custom_rmse_sixth: 0.7229 - val_loss: 2.3488\n",
      "Epoch 20/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - custom_mae_sixth: 0.5327 - custom_mape_sixth: 259.0245 - custom_rmse_sixth: 0.6899 - loss: 2.2146 - val_custom_mae_sixth: 0.6002 - val_custom_mape_sixth: 216.3684 - val_custom_rmse_sixth: 0.7425 - val_loss: 2.3187\n",
      "Epoch 21/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - custom_mae_sixth: 0.5384 - custom_mape_sixth: 288.9211 - custom_rmse_sixth: 0.7024 - loss: 2.1824 - val_custom_mae_sixth: 0.5914 - val_custom_mape_sixth: 199.0444 - val_custom_rmse_sixth: 0.7114 - val_loss: 2.2377\n",
      "Epoch 22/50\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 86ms/step - custom_mae_sixth: 0.5327 - custom_mape_sixth: 246.5360 - custom_rmse_sixth: 0.6952 - loss: 2.1251 - val_custom_mae_sixth: 0.6001 - val_custom_mape_sixth: 187.3810 - val_custom_rmse_sixth: 0.7364 - val_loss: 2.2216\n",
      "Epoch 23/50\n",
      "\u001b[1m 24/188\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - custom_mae_sixth: 0.4796 - custom_mape_sixth: 355.8633 - custom_rmse_sixth: 0.6266 - loss: 1.9918"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, LayerNormalization, LSTM, RepeatVector,\n",
    "    TimeDistributed, MultiHeadAttention, Concatenate, Bidirectional\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras_tuner import HyperParameters, RandomSearch\n",
    "\n",
    "# Carregar dados\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Converter 'id' em datetime e definir como índice\n",
    "data['timestamp'] = pd.to_datetime(data['id'], errors='coerce')\n",
    "data.set_index('timestamp', inplace=True)\n",
    "\n",
    "\n",
    "# Engenharia de Atributos\n",
    "data['ws100_diff'] = data['ws100'].diff()\n",
    "data['ws100_shift_1'] = data['ws100'].shift(1)\n",
    "data['ws100_roll_mean_3'] = data['ws100'].rolling(window=3).mean()\n",
    "data['ws100_roll_std_3'] = data['ws100'].rolling(window=3).std()\n",
    "data['ws100_roll_mean_6'] = data['ws100'].rolling(window=6).mean()\n",
    "data['ws100_roll_std_6'] = data['ws100'].rolling(window=6).std()\n",
    "\n",
    "# Remover os NaNs gerados pelas operações\n",
    "data = data.dropna()\n",
    "\n",
    "# Selecionar variáveis\n",
    "variables = data[['ws100', 'humid','wdisp100']].values\n",
    "\n",
    "# Padronização dos dados\n",
    "scaler = StandardScaler()\n",
    "variables_scaled = scaler.fit_transform(variables)\n",
    "\n",
    "# Parâmetros\n",
    "sequence_length = 36\n",
    "forecast_horizon = 6  # Não usado neste caso\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Divisão dos dados em treinamento e teste\n",
    "split_index = int(len(variables_scaled) * split_ratio)\n",
    "train_data = variables_scaled[:split_index]\n",
    "test_data = variables_scaled[split_index:]\n",
    "\n",
    "# Função para preparar sequências de dados\n",
    "def create_sequences(data, seq_length, target_step):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - target_step + 1):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length + target_step - 1, 0])  # 'ws100' no sexto passo futuro\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "target_step = 6  # Prever o sexto valor futuro\n",
    "\n",
    "# Criar sequências para treinamento e teste\n",
    "X_train, y_train = create_sequences(train_data, sequence_length, target_step)\n",
    "X_test, y_test = create_sequences(test_data, sequence_length, target_step)\n",
    "\n",
    "# Reshape de y_train e y_test para serem compatíveis com a saída do modelo\n",
    "y_train = y_train.reshape(-1, 1, 1)\n",
    "y_test = y_test.reshape(-1, 1, 1)\n",
    "\n",
    "# Obter média e desvio padrão de 'ws100' no conjunto de treinamento para inversão da padronização\n",
    "mean_ws100 = scaler.mean_[0]\n",
    "std_ws100 = np.sqrt(scaler.var_[0])\n",
    "\n",
    "# Definição das funções de perda personalizadas\n",
    "def custom_mse_sixth(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true[:, -1, 0] - y_pred[:, -1, 0]))\n",
    "\n",
    "def custom_mae_sixth(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true[:, -1, 0] - y_pred[:, -1, 0]))\n",
    "\n",
    "def custom_rmse_sixth(y_true, y_pred):\n",
    "    return tf.sqrt(custom_mse_sixth(y_true, y_pred))\n",
    "\n",
    "def custom_mape_sixth(y_true, y_pred):\n",
    "    epsilon = tf.keras.backend.epsilon()\n",
    "    y_true_sixth = y_true[:, -1, 0]\n",
    "    y_pred_sixth = y_pred[:, -1, 0]\n",
    "    return tf.reduce_mean(tf.abs((y_true_sixth - y_pred_sixth) / (tf.abs(y_true_sixth) + epsilon))) * 100\n",
    "\n",
    "# %%\n",
    "# Definição da função para construir o modelo otimizado\n",
    "def build_model_optimized(hp):\n",
    "    # Hiperparâmetros com espaços de busca reduzidos\n",
    "    units = hp.Int('units', min_value=128, max_value=256, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', [1e-4, 1e-3])\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=2, step=1)\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    \n",
    "    # Seleção do Otimizador\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    \n",
    "    # Encoder Input\n",
    "    encoder_inputs = tf.keras.Input(shape=(sequence_length, X_train.shape[2]), name='encoder_input')\n",
    "    encoder_outputs = encoder_inputs\n",
    "    \n",
    "    # Encoder Layers Bidirecionais\n",
    "    for i in range(num_layers):\n",
    "        encoder_outputs = Bidirectional(\n",
    "            LSTM(\n",
    "                units=units,\n",
    "                return_sequences=True,\n",
    "                activation='tanh',\n",
    "                dropout=dropout_rate,\n",
    "                kernel_regularizer=l2(1e-3),\n",
    "                name=f'encoder_lstm_{i}'\n",
    "            )\n",
    "        )(encoder_outputs)\n",
    "        encoder_outputs = LayerNormalization(name=f'encoder_norm_{i}')(encoder_outputs)\n",
    "    \n",
    "    # Encoder State (concatenado das direções forward e backward)\n",
    "    encoder_state = encoder_outputs[:, -1, :]\n",
    "    \n",
    "    # Decoder Input\n",
    "    decoder_inputs = RepeatVector(1, name='repeat_vector')(encoder_state)\n",
    "    decoder_outputs = decoder_inputs\n",
    "    \n",
    "    # Decoder Layers Bidirecionais\n",
    "    for i in range(num_layers):\n",
    "        decoder_outputs = Bidirectional(\n",
    "            LSTM(\n",
    "                units=units,\n",
    "                return_sequences=True,\n",
    "                activation='tanh',\n",
    "                dropout=dropout_rate,\n",
    "                kernel_regularizer=l2(1e-3),\n",
    "                name=f'decoder_lstm_{i}'\n",
    "            )\n",
    "        )(decoder_outputs)\n",
    "        decoder_outputs = LayerNormalization(name=f'decoder_norm_{i}')(decoder_outputs)\n",
    "    \n",
    "    # Atenção Multi-Cabeça (adaptada para bidirecional)\n",
    "    attention = MultiHeadAttention(\n",
    "        num_heads=hp.Int('num_heads', min_value=2, max_value=4, step=2),\n",
    "        key_dim=units*2,  # Dobrando as unidades devido à bidirecionalidade\n",
    "        name='multi_head_attention'\n",
    "    )(decoder_outputs, encoder_outputs)\n",
    "    \n",
    "    attention = Dropout(dropout_rate, name='attention_dropout')(attention)\n",
    "    decoder_concat_input = Concatenate(axis=-1, name='concat_attention')([decoder_outputs, attention])\n",
    "    \n",
    "    # Camada de Saída\n",
    "    outputs = TimeDistributed(Dense(1, activation='linear'), name='output_layer')(decoder_concat_input)\n",
    "    \n",
    "    # Definição do Modelo\n",
    "    model = Model(inputs=encoder_inputs, outputs=outputs, name='Wind_Speed_Predictor_Bidirectional')\n",
    "    \n",
    "    # Compilação do Modelo\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=custom_mse_sixth,  # Usando a classe de perda customizada\n",
    "        metrics=[\n",
    "            custom_mae_sixth,\n",
    "            custom_rmse_sixth,\n",
    "            custom_mape_sixth        \n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "# %%\n",
    "# Otimização de hiperparâmetros com o Keras Tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model_optimized,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='wind_speed_prediction_optimized'\n",
    ")\n",
    "\n",
    "# Early stopping para evitar overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "# Iniciar a busca de hiperparâmetros\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A total of 11 objects could not be loaded. Example error message for object <LSTMCell name=lstm_cell, built=True>:\n\nLayer 'lstm_cell' expected 3 variables, but received 0 variables during loading. Expected: ['kernel', 'recurrent_kernel', 'bias']\n\nList of objects that could not be loaded:\n[<LSTMCell name=lstm_cell, built=True>, <LSTMCell name=lstm_cell, built=True>, <LayerNormalization name=encoder_norm_0, built=True>, <LSTMCell name=lstm_cell, built=True>, <LSTMCell name=lstm_cell, built=True>, <LayerNormalization name=decoder_norm_0, built=True>, <EinsumDense name=key, built=True>, <EinsumDense name=attention_output, built=True>, <EinsumDense name=query, built=True>, <EinsumDense name=value, built=True>, <Dense name=dense, built=True>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %% Obter os Melhores Hiperparâmetros e o Melhor Modelo\u001b[39;00m\n\u001b[1;32m      2\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Não há necessidade de carregar pesos manualmente\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# best_model.load_weights(best_trial.model_checkpoint_path)  # Remova esta linha\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# %% Avaliação do Melhor Modelo\u001b[39;00m\n\u001b[1;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:400\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:366\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[0;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(trial) \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:366\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[0;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:331\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Reload best checkpoint.\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Only load weights to avoid loading `custom_objects`.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_strategy):\n\u001b[0;32m--> 331\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_checkpoint_fname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Projetos/TFG-Vento-Sul/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:593\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[0;34m(error_msgs, warn_only)\u001b[0m\n\u001b[1;32m    591\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: A total of 11 objects could not be loaded. Example error message for object <LSTMCell name=lstm_cell, built=True>:\n\nLayer 'lstm_cell' expected 3 variables, but received 0 variables during loading. Expected: ['kernel', 'recurrent_kernel', 'bias']\n\nList of objects that could not be loaded:\n[<LSTMCell name=lstm_cell, built=True>, <LSTMCell name=lstm_cell, built=True>, <LayerNormalization name=encoder_norm_0, built=True>, <LSTMCell name=lstm_cell, built=True>, <LSTMCell name=lstm_cell, built=True>, <LayerNormalization name=decoder_norm_0, built=True>, <EinsumDense name=key, built=True>, <EinsumDense name=attention_output, built=True>, <EinsumDense name=query, built=True>, <EinsumDense name=value, built=True>, <Dense name=dense, built=True>]"
     ]
    }
   ],
   "source": [
    "# %% Obter os Melhores Hiperparâmetros e o Melhor Modelo\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Não há necessidade de carregar pesos manualmente\n",
    "# best_model.load_weights(best_trial.model_checkpoint_path)  # Remova esta linha\n",
    "\n",
    "# %% Avaliação do Melhor Modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Inversão da padronização\n",
    "y_pred_inv = y_pred[:, -1, 0] * std_ws100 + mean_ws100\n",
    "y_test_inv = y_test[:, -1, 0] * std_ws100 + mean_ws100\n",
    "\n",
    "# Métricas de desempenho\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "mape = np.mean(np.abs((y_test_inv - y_pred_inv) / y_test_inv)) * 100\n",
    "\n",
    "print(f\"MAE no sexto passo: {mae:.2f}\")\n",
    "print(f\"RMSE no sexto passo: {rmse:.2f}\")\n",
    "print(f\"MAPE no sexto passo: {mape:.2f}%\")\n",
    "\n",
    "# Plotagem das previsões\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_inv, label='Valor Real - Passo 6')\n",
    "plt.plot(y_pred_inv, label='Previsão - Passo 6')\n",
    "plt.legend()\n",
    "plt.title('Comparação entre Valores Reais e Previstos no Sexto Passo (Modelo Otimizado)')\n",
    "plt.xlabel('Amostras')\n",
    "plt.ylabel('Velocidade do Vento a 100 metros')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
