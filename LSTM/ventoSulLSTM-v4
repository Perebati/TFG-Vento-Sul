import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import TimeSeriesSplit
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LSTM, Dense, InputLayer, Dropout, Reshape, RepeatVector, TimeDistributed, Input, Attention, Concatenate
from tensorflow.keras.callbacks import EarlyStopping
import kerastuner as kt
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

# Load the dataset
df = pd.read_csv("dataset.csv")
df.index = pd.to_datetime(df["id"], errors="ignore")

# Columns for training
cols = ["humid", "ws100", "wdisp100", "vertdisp100"]
df_for_training = df[cols].astype(float)

# Feature Engineering: Create lagged features
for lag in range(1, 4):  # Lag of 1 to 3 time steps
    lagged_df = df_for_training.shift(lag).add_suffix(f'_lag_{lag}')
    df_for_training = pd.concat([df_for_training, lagged_df], axis=1)

# Drop rows with NaN values caused by shifting
df_for_training.dropna(inplace=True)

# Scaling with MinMaxScaler
scaler = MinMaxScaler()
df_for_training_scaled = scaler.fit_transform(df_for_training)

# Define sequence and prediction lengths
sequence_length = 36  # Last 6 hours (36 values)
prediction_length = 6  # Next 1 hour (6 values)

X, y = [], []

# Prepare sequences for input and output
for i in range(len(df_for_training_scaled) - sequence_length - prediction_length + 1):
    X.append(df_for_training_scaled[i: i + sequence_length])
    y.append(df_for_training_scaled[i + sequence_length: i + sequence_length + prediction_length, :len(cols)])  # Predicting original cols

X = np.array(X)
y = np.array(y)

print(f"Shape of X: {X.shape}")  # (samples, 36, features)
print(f"Shape of y: {y.shape}")  # (samples, 6, features)

# Manual train-test split
train_size = int(len(X) * 0.8)
X_train = X[:train_size]
y_train = y[:train_size]
X_test = X[train_size:]
y_test = y[train_size:]

# Hyperparameter Tuning with KerasTuner
def build_model(hp):
    inputs = Input(shape=(sequence_length, X.shape[2]))
    encoder_outputs, state_h, state_c = LSTM(
        units=hp.Int('units', min_value=64, max_value=256, step=64),
        return_state=True
    )(inputs)
    decoder_inputs = RepeatVector(prediction_length)(state_h)
    decoder_outputs = LSTM(
        units=hp.Int('units', min_value=64, max_value=256, step=64),
        return_sequences=True
    )(decoder_inputs, initial_state=[state_h, state_c])
    attention = Attention()([decoder_outputs, encoder_outputs])
    decoder_concat_input = Concatenate(axis=-1)([decoder_outputs, attention])
    outputs = TimeDistributed(Dense(len(cols), activation='linear'))(decoder_concat_input)
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(
        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-3, 1e-4])),
        loss='mse'
    )
    return model

tuner = kt.RandomSearch(
    build_model,
    objective='val_loss',
    max_trials=3,
    executions_per_trial=1,
    directory='tuner_dir',
    project_name='wind_speed_prediction'
)

tuner.search(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=10,
    callbacks=[EarlyStopping(monitor='val_loss', patience=3)],
    verbose=1
)

best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(f"Best hyperparameters: Units: {best_hps.get('units')}, Learning Rate: {best_hps.get('learning_rate')}")

# Build the model with best hyperparameters
model = build_model(best_hps)
model.summary()

# Time Series Cross-Validation
tscv = TimeSeriesSplit(n_splits=5)
fold = 1
for train_index, test_index in tscv.split(X_train):
    print(f"Fold {fold}")
    X_train_cv, X_val_cv = X_train[train_index], X_train[test_index]
    y_train_cv, y_val_cv = y_train[train_index], y_train[test_index]

    # Training
    model.fit(
        X_train_cv, y_train_cv,
        validation_data=(X_val_cv, y_val_cv),
        epochs=10,
        callbacks=[EarlyStopping(monitor='val_loss', patience=3)],
        verbose=1
    )

    fold += 1

# Final evaluation on the test set
y_pred = model.predict(X_test)

# Inverse transform to original scale
y_pred_reshaped = y_pred.reshape(-1, len(cols))
y_pred_orig = scaler.inverse_transform(np.hstack([y_pred_reshaped, np.zeros((y_pred_reshaped.shape[0], df_for_training.shape[1] - len(cols)))]))
y_pred_orig = y_pred_orig[:, :len(cols)].reshape(-1, prediction_length, len(cols))

y_test_reshaped = y_test.reshape(-1, len(cols))
y_test_orig = scaler.inverse_transform(np.hstack([y_test_reshaped, np.zeros((y_test_reshaped.shape[0], df_for_training.shape[1] - len(cols)))]))
y_test_orig = y_test_orig[:, :len(cols)].reshape(-1, prediction_length, len(cols))

# Evaluate the sixth predicted value
for i, col in enumerate(cols):
    y_true = y_test_orig[:, 5, i]  # Sixth value (index 5)
    y_pred_col = y_pred_orig[:, 5, i]

    rmse = np.sqrt(np.mean((y_true - y_pred_col) ** 2))
    nrmse = rmse / (y_true.max() - y_true.min())
    relative_error = (np.mean(np.abs((y_true - y_pred_col) / y_true)) * 100)

    print(f"'{col}': RMSE = {rmse:.4f}, NRMSE = {nrmse:.4f}, Relative Error = {relative_error:.2f}%")

    # Plotting
    plt.figure(figsize=(10, 6))
    plt.plot(y_true, label=f"Actual Value ({col})", alpha=0.7)
    plt.plot(y_pred_col, label=f"Prediction ({col})", alpha=0.7)
    plt.legend()
    plt.title(f"Prediction vs Actual Value - Sixth Value - {col}")
    plt.show()
